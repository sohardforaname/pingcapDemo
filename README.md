# pingcapDemo

这是一个pingcap实习应聘小作业。
## 题目

某个机器的配置为：CPU 8 cores, memory 4G, HDD 4T，这个机器上有一个 1T 的无序数据文件，格式为 (key_size, key, value_size, value)，设计一个索引结构，使得并发随机地读取每一个 key-value 的代价最小。

## 想法和设计

- 考虑到最短的k-v: 
  - key_size: 1bytes, space: 1bytes, key: 1bytes, space: 1bytes;
  - val_size: 1bytes, space: 1bytes, value: 1bytes, space: 1bytes;
  - 一共8byte。
  - 在1T的文件里面最多有128G个k-v。

- 考虑对文件分块，分成1024块，每块1Gbytes，或者是2048块，每块512Mbytes，或者更小的。

- 建立简单的哈希表，维护新的键值对new_k-v：(key: uint64, value: uint64)，或者(key:uint32, value:uint32)，其中key是文件中key的哈希值，value是该k-v的文件偏移量。
  - 考虑32位系统，一个哈希表包括哈希桶和链表构成。
  - 一个链表节点指针是4bytes, value是4bytes，一共8bytes。一个桶中链表头指针节点是4bytes。
  - 所以如果使用桶的数量是0x10000000u，且每0x00080000个桶放到一个文件中，一共256个文件，使用BKDR Hash算法尽可能保证均匀。
  - 平均一个文件512Mbytes。
  - 以上策略也可以调整参数获得最优情况（比如说按照CPU的Cache还有页表大小啥的调参）。

- 具体的算法：
  - 初次使用时，创建一个哈希表，初始化所有的链表头结点指针是-1，直接写入文件中。 
  - 每次加载一个块进文件。
  - 然后对这个文件里面的键进行哈希，然后把该哈希桶对应的文件加载到内存中。（实现时也可以把这个块里面的数据批量哈希，然后对哈希值排序，再分别写入对应的哈希桶中）。
  - 剩下的文件块如法炮制。
  - 查询时直接查对应的哈希桶，然后把相关key的文件偏移量找出来，读取k-v然后返回即可。

- 并发
  - TODO

- 时间复杂度
  - 预处理是大概是O(nlogn)级别的，因为需要排序，但是我觉得不排序直接插的话虽然是O(1)的，但是访存时间可能就抵消掉了时间复杂度的优势。
  - 查询就是O(1)的，当然访存还是个大问题。
  - 当然，虽然说是O(1)，因为数据量太大，桶的数量又比较小，所以考虑所有桶都平均的话，每次最坏要找400个k-v。
  - 实际编写代码时为了方便测试，所有参数都会相应缩小，但是计算表明内存是足够的。

## Release 1.0.0

完成了基本功能，但是程序是单线程顺序执行的。为了方便测试，桶的数量只有2^23个，buffer的大小也是2^23bytes。
