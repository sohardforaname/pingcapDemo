# pingcapDemo

这是一个pingcap实习应聘小作业。
## 题目

某个机器的配置为：CPU 8 cores, memory 4G, HDD 4T，这个机器上有一个 1T 的无序数据文件，格式为 (key_size, key, value_size, value)，设计一个索引结构，使得并发随机地读取每一个 key-value 的代价最小。

## 想法和设计

- 考虑到最短的k-v: 
  - key_size: 1bytes, space: 1bytes, key: 1bytes, space: 1bytes;
  - val_size: 1bytes, space: 1bytes, value: 1bytes, space: 1bytes;
  - 一共8byte。
  - 在1T的文件里面最多有128G个k-v。

- 考虑对文件分块，分成1024块，每块1Gbytes，或者是2048块，每块512Mbytes，或者更小的。

- 建立简单的哈希表，维护新的键值对new_k-v：(key: uint64, value: uint64)，或者(key:uint32, value:uint32)，其中key是文件中key的哈希值，value是该k-v的文件偏移量。
  - 考虑32位系统，一个哈希表包括哈希桶和链表构成。
  - 一个链表节点指针是4bytes, value是4bytes，一共8bytes。一个桶中链表头指针节点是4bytes。
  - 所以如果使用桶的数量是0x10000000u，且每0x00080000个桶放到一个文件中，一共256个文件，使用BKDR Hash算法尽可能保证均匀。
  - 平均一个文件512Mbytes。
  - 以上策略也可以调整参数获得最优情况（比如说按照CPU的Cache还有页表大小啥的调参）。

- 具体的算法：
  - 初次使用时，创建一个哈希表，初始化所有的链表头结点指针是-1，直接写入文件中。 
  - 每次加载一个块进文件。
  - 然后对这个文件里面的键进行哈希，然后把该哈希桶对应的文件加载到内存中。（实现时也可以把这个块里面的数据批量哈希，然后对哈希值排序，再分别写入对应的哈希桶中）。
  - 剩下的文件块如法炮制。
  - 查询时直接查对应的哈希桶，然后把相关key的文件偏移量找出来，读取k-v然后返回即可。

- 并发
  - TODO

- 时间复杂度
  - 预处理是大概是O(nlogn)级别的，因为需要排序，但是我觉得不排序直接插的话虽然是O(1)的，但是访存时间可能就抵消掉了时间复杂度的优势。
  - 查询就是O(1)的，当然访存还是个大问题。
  - 当然，虽然说是O(1)，因为数据量太大，桶的数量又比较小，所以考虑所有桶都平均的话，每次最坏要找400个k-v。
  - 实际编写代码时为了方便测试，所有参数都会相应缩小，但是计算表明内存是足够的。

## Release 1.0.0 2020.3.6

完成了基本功能，但是程序是单线程顺序执行的。为了方便测试，桶的数量只有2^23个，buffer的大小也是2^21bytes，测试小数据是正确的（1000个k-v），但是大一点的数据集就会出现bug。

## Release 1.0.1 2020.3.7

经过排查，发现是如果多次调用fread函数，ftell函数的行为就会十分怪异，不符合实际的情况，如某一次测试，连续使用4次fread，buffer是16，中间没有使用fseek，每次读取前的ftell返回值是0,17,34,51。查找资料后，资料均显示是文件指针当前位置和首字节的距离，但是显然不符合现在的情况，可能是我的理解不对？所以小数据正确的原因是，只调用了一次fread函数。因为ftell函数的问题，我的代码需要大改，时间上已经不足，所以只能遗憾地通过小数据，不能达到题目的全部要求。（猜想，是不是每次使用了ftell和fread这些函数之后，都得尽量使用fseek使得文件指针去到你希望去的位置？）

所以我只能提供上述dat数据集下的测试结果（桶的数量是2^23个，buffer大小是2^21bytes（主要是考虑windows的Huge Page大小是2Mbytes））：
处理这1000个k-v耗时716ms，每个k-v的查询时间是1.7ms左右。

总的来说这是我第一次写硬盘的文件和内存频繁交互的程序，之前写的所有程序都是基于内存的，即使需要用到文件，也是只管fread就行，根本不需要ftell，fseek这些精细的文件操作，所以写这个程序还是耗费了我挺多精力思考和debug，和复习文件操作。但是最终还是留下了一点遗憾。

## 补充

查资料的时候忘记了cppreference这玩意了，就去查了一下cppreference，好家伙，这才发现ftell要和fseek配套使用，或者是二进制文件，否则是UB，同理fgetpos也要和fsetpos配套使用，难怪我的索引文件无事发生，k-v的数据文件一直出bug。吃一堑长一智了。（其他博客都没提到这茬，看来以后查资料，还得靠cppreference和源码，博客只能用来查查简单的小问题）。

## fix fflush

又找了一些bug，发现fflush忘写了，赶紧加上。

## ftell的原因和解决方法

其实是因为windows系统上\r导致的，我造了一些单条k-v长一点的数据，这个问题就没了，所以一个简单的方法就是用二进制模式打开k-v文件，bug就消除了。

## Release 1.0.4 2020.3.9

解决了之前说的bug，但是Reader那里还有新的问题出现，课设比较紧张，暂时没有时间修bug了（因为可能是设计的问题，需要重构），现在最新的版本可以运行70000个k-v的数据集。运行这个数据集建立索引需要25000ms左右，单次查找时间是1.6ms。
